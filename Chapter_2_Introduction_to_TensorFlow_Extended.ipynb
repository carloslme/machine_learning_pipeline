{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_2_Introduction_to_TensorFlow_Extended.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObGIIIeeHx43V6w1xEtgnL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carloslme/machine_learning_pipeline/blob/chapter2/Chapter_2_Introduction_to_TensorFlow_Extended.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_rlbvhLHEcP"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_iF9jVLMuu"
      },
      "source": [
        "!pip install tfx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HSecrHoKA_I"
      },
      "source": [
        "import tensorflow_data_validation as tfdv\r\n",
        "import tensorflow_transform as tft\r\n",
        "import tensorflow_transform.beam as tft_beam"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjayCdg9LLDf"
      },
      "source": [
        "from tfx.components import ExampleValidator \r\n",
        "from tfx.components import Evaluator \r\n",
        "from tfx.components import Transform\r\n",
        "from tfx.components import CsvExampleGen"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGCL_L0BNWHz"
      },
      "source": [
        "### Overview of TFX Components\r\n",
        "The generic internals of a component are always: \r\n",
        "* Receive some input \r\n",
        "* Perform an action \r\n",
        "* Store the final result\r\n",
        "\r\n",
        "In TFX terms, the three internal parts of the component are called the driver , executor , and publisher . The driver handles the querying of the metadata store. The executor performs the actions of the components. And the publisher manages the saving of the output metadata in the MetadataStore.\r\n",
        "\r\n",
        "The inputs and outputs of the components are called artifacts . Examples of artifacts include raw input data, preprocessed data, and trained models. Each artifact is associated with metadata stored in the MetadataStore. The artifact metadata consists of an artifact type as well as artifact properties. This artifact setup guarantees that the components can exchange data effectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvNnKrViDSPL",
        "outputId": "3542ef70-8167-4827-bad4-4709ff643bbb"
      },
      "source": [
        "!rm -rf /content/PetImages/\r\n",
        "!rm *.zip\r\n",
        "\r\n",
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\r\n",
        "!unzip -q -d /content/ /content/kagglecatsanddogs_3367a.zip\r\n",
        "\r\n",
        "!echo \"Count images\"\r\n",
        "!ls -U /content/PetImages/Cat | wc -l\r\n",
        "!ls -U /content/PetImages/Dog | wc -l\r\n",
        "\r\n",
        "!echo \"Reduce images for demo purposes\"\r\n",
        "!cd /content/PetImages/Cat && ls -U | head -12000 | xargs rm \r\n",
        "!cd /content/PetImages/Dog && ls -U | head -12000 | xargs rm \r\n",
        "\r\n",
        "!echo \"Count images after removal\"\r\n",
        "!ls -U /content/PetImages/Cat | wc -l\r\n",
        "!ls -U /content/PetImages/Dog | wc -l"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.zip': No such file or directory\n",
            "--2021-01-24 06:20:38--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.53.252.195, 2600:1406:3:496::e59, 2600:1406:3:491::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.53.252.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs_3367a.zip’\n",
            "\n",
            "kagglecatsanddogs_3 100%[===================>] 786.68M  99.3MB/s    in 7.7s    \n",
            "\n",
            "2021-01-24 06:20:46 (102 MB/s) - ‘kagglecatsanddogs_3367a.zip’ saved [824894548/824894548]\n",
            "\n",
            "Count images\n",
            "12501\n",
            "12501\n",
            "Reduce images for demo purposes\n",
            "Count images after removal\n",
            "501\n",
            "501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9rVjoKcEg0X"
      },
      "source": [
        "!pip install -qU tfx\r\n",
        "\r\n",
        "import tfx \r\n",
        "\r\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Hiq5TLEj84",
        "outputId": "264093e8-7bb2-4ec5-83fd-b5747e46b9d3"
      },
      "source": [
        "%%skip_for_export\r\n",
        "\r\n",
        "import IPython\r\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "text": [
            "This cell will be skipped during export to pipeline.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mvKjwNSEyqv",
        "outputId": "1aae2328-a75a-49ea-9e0b-23ae94d586f6"
      },
      "source": [
        "%%skip_for_export\r\n",
        "%%writefile constants.py\r\n",
        "\r\n",
        "from typing import Text\r\n",
        "\r\n",
        "def transformed_name(key: Text) -> Text:\r\n",
        "  \"\"\"Generate the name of the transformed feature from original name.\"\"\"\r\n",
        "  return key + '_xf'\r\n",
        "\r\n",
        "# Keys\r\n",
        "LABEL_KEY = 'label'\r\n",
        "INPUT_KEY = 'image/raw'\r\n",
        "\r\n",
        "# Feature keys\r\n",
        "RAW_FEATURE_KEYS = [INPUT_KEY]\r\n",
        "\r\n",
        "# Constants\r\n",
        "IMG_SIZE = 160"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Cell magic `%%skip_for_export` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jd9tTnXiErUd",
        "outputId": "41e72552-9bdc-4f89-8759-33c67f45997e"
      },
      "source": [
        "# Keys\r\n",
        "LABEL_KEY = 'label'\r\n",
        "INPUT_KEY = 'image/raw'\r\n",
        "\r\n",
        "import base64\r\n",
        "import logging\r\n",
        "import os\r\n",
        "import random\r\n",
        "import re\r\n",
        "import sys\r\n",
        "from typing import Any, Dict, Iterable, List, Text\r\n",
        "\r\n",
        "import absl\r\n",
        "import apache_beam as beam\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_model_analysis as tfma\r\n",
        "import tfx\r\n",
        "from google.protobuf import json_format\r\n",
        "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\r\n",
        "from tensorflow_transform.saved import saved_transform_io\r\n",
        "from tensorflow_transform.tf_metadata import (dataset_metadata, dataset_schema,\r\n",
        "                                              metadata_io, schema_utils)\r\n",
        "from tfx import types\r\n",
        "from tfx.components import (Evaluator, Pusher, ResolverNode, StatisticsGen,\r\n",
        "                            Trainer)\r\n",
        "from tfx.components.base import (base_component, base_driver, base_executor,\r\n",
        "                                 executor_spec)\r\n",
        "from tfx.components.example_gen import driver\r\n",
        "from tfx.components.example_gen.base_example_gen_executor import (\r\n",
        "    INPUT_KEY, BaseExampleGenExecutor)\r\n",
        "from tfx.components.example_gen.component import FileBasedExampleGen\r\n",
        "from tfx.components.example_gen.import_example_gen.component import \\\r\n",
        "    ImportExampleGen\r\n",
        "from tfx.components.example_gen.utils import dict_to_example\r\n",
        "from tfx.components.example_validator.component import ExampleValidator\r\n",
        "from tfx.components.schema_gen.component import SchemaGen\r\n",
        "from tfx.components.statistics_gen.component import StatisticsGen\r\n",
        "from tfx.components.trainer.executor import GenericExecutor\r\n",
        "from tfx.components.transform.component import Transform\r\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\r\n",
        "from tfx.orchestration import data_types, metadata, pipeline\r\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\r\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import \\\r\n",
        "    InteractiveContext\r\n",
        "from tfx.proto import evaluator_pb2, example_gen_pb2, pusher_pb2, trainer_pb2\r\n",
        "from tfx.types import (Channel, artifact_utils, channel_utils,\r\n",
        "                       standard_artifacts)\r\n",
        "from tfx.types.component_spec import ChannelParameter, ExecutionParameter\r\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\r\n",
        "from tfx.utils import io_utils\r\n",
        "from tfx.utils.dsl_utils import external_input\r\n",
        "\r\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-64aec313f30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                  executor_spec)\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_gen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m from tfx.components.example_gen.base_example_gen_executor import (\n\u001b[0m\u001b[1;32m     30\u001b[0m     INPUT_KEY, BaseExampleGenExecutor)\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexample_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileBasedExampleGen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'INPUT_KEY'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVab1BCn8FsR"
      },
      "source": [
        "### Interactive pipelines\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi_7PeL2NHTH"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wZE853Gc_y-T",
        "outputId": "938077c8-3019-4583-df24-e70baf34ce99"
      },
      "source": [
        "from tfx.utils.dsl_utils import external_input\r\n",
        "\r\n",
        "example_gen = CsvExampleGen(input=external_input(data_path))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6914f351015c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsl_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexternal_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexample_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCsvExampleGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexternal_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "kquUG1dT8O3N",
        "outputId": "6ff03f16-cbec-4c84-927b-3e308bfb2293"
      },
      "source": [
        "context = InteractiveContext()\r\n",
        "from tfx.components import StatisticsGen \r\n",
        "statistics_gen = StatisticsGen(\r\n",
        "     examples = example_gen.outputs['examples'])\r\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2021-01-24T05_58_03.441829-b8jawsze as root for pipeline outputs.\n",
            "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2021-01-24T05_58_03.441829-b8jawsze/metadata.sqlite.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e92a21de7da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStatisticsGen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m statistics_gen = StatisticsGen(\n\u001b[0;32m----> 4\u001b[0;31m      examples = example_gen.outputs['examples'])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'example_gen' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFnhM4f9YGt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi-w0BcpEfiI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gGFQWgBHIDs"
      },
      "source": [
        "# Apache Beam Word Count Example\r\n",
        "How to carry out a simple data transformation using Beam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qz37GLOHHRF"
      },
      "source": [
        "!pip install -q apache_beam[gcp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-6Ar4PfHOsg"
      },
      "source": [
        "\r\n",
        "import re\r\n",
        "\r\n",
        "import apache_beam as beam\r\n",
        "from apache_beam.io import ReadFromText\r\n",
        "from apache_beam.io import WriteToText\r\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\r\n",
        "from apache_beam.options.pipeline_options import SetupOptions\r\n",
        "\r\n",
        "input_file = \"gs://dataflow-samples/shakespeare/kinglear.txt\"\r\n",
        "output_file = \"/content/output.txt\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "KPfbJBUoHhwu",
        "outputId": "8d205644-c0d2-426e-d6ea-4a64a0abdb3d"
      },
      "source": [
        "\r\n",
        "# TODO explain these lines\r\n",
        "pipeline_options = PipelineOptions()\r\n",
        "# pipeline_options.view_as(SetupOptions).save_main_session = True\r\n",
        "\r\n",
        "with beam.Pipeline(options=pipeline_options) as p: # Use the context manager to define the pipeline.\r\n",
        "\r\n",
        "    # Read the text file[pattern] into a PCollection.\r\n",
        "    lines = p | ReadFromText(input_file)\r\n",
        "\r\n",
        "    # Count the occurrences of each word.\r\n",
        "    counts = (\r\n",
        "        lines\r\n",
        "        | 'Split' >> (beam.FlatMap(lambda x: re.findall(r'[A-Za-z\\']+', x)))\r\n",
        "                      # .with_output_types(unicode))\r\n",
        "        | 'PairWithOne' >> beam.Map(lambda x: (x, 1))\r\n",
        "        | 'GroupAndSum' >> beam.CombinePerKey(sum))\r\n",
        "\r\n",
        "    # Format the counts into a PCollection of strings.\r\n",
        "    def format_result(word_count):\r\n",
        "        (word, count) = word_count\r\n",
        "        return '%s: %s' % (word, count)\r\n",
        "\r\n",
        "    output = counts | 'Format' >> beam.Map(format_result)\r\n",
        "\r\n",
        "    # Write the output using a \"Write\" transform that has side effects.\r\n",
        "    output | WriteToText(output_file)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.internal.gcp.auth:Unable to find default credentials to use: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.\n",
            "Connecting anonymously.\n",
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sn4MD8AHwl9",
        "outputId": "c9ee59b0-7b0b-4ece-b4a0-6001b22de45d"
      },
      "source": [
        "!head /content/output.txt*"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KING: 243\n",
            "LEAR: 236\n",
            "DRAMATIS: 1\n",
            "PERSONAE: 1\n",
            "king: 65\n",
            "of: 447\n",
            "Britain: 2\n",
            "OF: 15\n",
            "FRANCE: 10\n",
            "DUKE: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXmzteajINnm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}